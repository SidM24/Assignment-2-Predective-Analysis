{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfe3000c-cb45-4a7b-9cd1-7c497cdc8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cade6c2f-9d1c-44b8-9aac-9d8df0ab396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Creditcard_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c56ca08e-39bd-4c6e-92a2-1789eb586560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python312\\lib\\site-packages (from imbalanced-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\python312\\lib\\site-packages (from imbalanced-learn) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\python312\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python312\\lib\\site-packages (from imbalanced-learn) (3.2.0)\n",
      "Downloading imbalanced_learn-0.12.0-py3-none-any.whl (257 kB)\n",
      "   ---------------------------------------- 0.0/257.7 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/257.7 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/257.7 kB 435.7 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 61.4/257.7 kB 544.7 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 112.6/257.7 kB 656.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 225.3/257.7 kB 981.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 257.7/257.7 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4cf3a99-6a07-40c3-a0e6-3dacddd4972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaba9d37-b0d9-4951-aecf-638fea5ab076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "# Fit the model to generate the data.\n",
    "oversampled_X, oversampled_Y = sm.fit_resample(data.drop('Class', axis=1), data['Class'])\n",
    "oversampled = pd.concat([pd.DataFrame(oversampled_Y), pd.DataFrame(oversampled_X)], axis=1)\n",
    "new_data=oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e88bf3a0-4fdd-40ec-8c83-9f0942947b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled['Class'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99e95f51-10ec-4066-99f3-19df361bf09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Random Sampling\n",
    "Simple_random_sample = new_data.sample(frac=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3941fb4-1930-4c84-a626-2ba3e8c50c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Systematic Sampling\n",
    "k = 2\n",
    "# Randomly select the starting point from the first k items\n",
    "start_point = pd.DataFrame(new_data.sample(k, random_state=42))\n",
    "\n",
    "# Perform systematic sampling\n",
    "systematic_sample= new_data.iloc[start_point.index[0]::k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94d34f7c-b9d7-43c0-b0f6-6f4e0d30243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stratified Sampling based on the Class Column\n",
    "from sklearn.model_selection import train_test_split\n",
    "stratify_column = 'Class'\n",
    "\n",
    "# Perform stratified sampling\n",
    "stratify_train_data, stratify_test_data = train_test_split(new_data, test_size=0.2, stratify=new_data[stratify_column], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d229ff95-fa7f-4060-9b86-f943c8b163f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster Sampling\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "temp_data=new_data\n",
    "\n",
    "# Specify the number of clusters for cluster sampling\n",
    "num_clusters = 5\n",
    "\n",
    "# Shuffle the columns of the DataFrame\n",
    "shuffled_columns = temp_data.sample(frac=1, axis=1, random_state=42)\n",
    "\n",
    "# Choose a random subset of columns for clustering (e.g., first two columns)\n",
    "num_features_for_clustering = 2\n",
    "features_for_clustering = shuffled_columns.iloc[:, :num_features_for_clustering]\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "temp_data['Cluster'] = kmeans.fit_predict(features_for_clustering)\n",
    "\n",
    "# Select random clusters for cluster sampling\n",
    "selected_clusters = temp_data['Cluster'].sample(2, random_state=42).tolist()\n",
    "\n",
    "# Perform cluster sampling by selecting all elements from the selected clusters\n",
    "cluster_sampled_data = temp_data[temp_data['Cluster'].isin(selected_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bd8753c-00e7-426f-931f-d6f1658939ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class      662\n",
       "Time       662\n",
       "V1         662\n",
       "V2         662\n",
       "V3         662\n",
       "V4         662\n",
       "V5         662\n",
       "V6         662\n",
       "V7         662\n",
       "V8         662\n",
       "V9         662\n",
       "V10        662\n",
       "V11        662\n",
       "V12        662\n",
       "V13        662\n",
       "V14        662\n",
       "V15        662\n",
       "V16        662\n",
       "V17        662\n",
       "V18        662\n",
       "V19        662\n",
       "V20        662\n",
       "V21        662\n",
       "V22        662\n",
       "V23        662\n",
       "V24        662\n",
       "V25        662\n",
       "V26        662\n",
       "V27        662\n",
       "V28        662\n",
       "Amount     662\n",
       "Cluster    662\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c5ef0-e078-4da2-b646-fe4456149833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
